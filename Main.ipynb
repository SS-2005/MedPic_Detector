{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNko0rqbLS/P5/QDFXj2eHt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SS-2005/MedPic_Detector/blob/main/Main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Complete Medical Image Classification System for Google Colab\n",
        "!pip install tensorflow opencv-python requests beautifulsoup4 pymupdf Pillow tqdm pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hvmqudnoi0qj",
        "outputId": "f8f2eed7-8fae-4438-f6cb-c68b7340f5b8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.19.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.4)\n",
            "Collecting pymupdf\n",
            "  Downloading pymupdf-1.26.3-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (11.3.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.14.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.74.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.8.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.7)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Downloading pymupdf-1.26.3-cp39-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymupdf\n",
            "Successfully installed pymupdf-1.26.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import urljoin\n",
        "from io import BytesIO\n",
        "import fitz  # PyMuPDF\n",
        "import re\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from google.colab import files\n",
        "import shutil"
      ],
      "metadata": {
        "id": "ER18G7_bi0nd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================\n",
        "# 1. IMAGE EXTRACTION\n",
        "# ======================\n",
        "HEADERS = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36',\n",
        "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8',\n",
        "    'Accept-Language': 'en-US,en;q=0.9',\n",
        "    'Referer': 'https://www.google.com/',\n",
        "    'Connection': 'keep-alive',\n",
        "    'Upgrade-Insecure-Requests': '1',\n",
        "}\n",
        "\n",
        "def extract_images_from_url(url, output_dir=\"extracted_images\"):\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    image_paths = []\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url, headers=HEADERS, timeout=10)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "        img_tags = soup.find_all('img')\n",
        "\n",
        "        for i, img_tag in enumerate(img_tags):\n",
        "            img_url = img_tag.get('src') or img_tag.get('data-src')\n",
        "            if not img_url:\n",
        "                continue\n",
        "\n",
        "            img_url = urljoin(url, img_url)\n",
        "\n",
        "            try:\n",
        "                img_response = requests.get(img_url, headers=HEADERS, stream=True, timeout=10)\n",
        "                img_response.raise_for_status()\n",
        "\n",
        "                content_type = img_response.headers.get('content-type', '')\n",
        "                if 'image' not in content_type:\n",
        "                    continue\n",
        "\n",
        "                # Get file extension\n",
        "                ext = 'jpg'  # default\n",
        "                if 'image/' in content_type:\n",
        "                    ext = content_type.split('/')[-1].split(';')[0]\n",
        "                elif '.' in img_url.split('/')[-1].split('?')[0]:\n",
        "                    ext = img_url.split('/')[-1].split('.')[-1].split('?')[0]\n",
        "\n",
        "                # Clean extension\n",
        "                ext = re.sub(r'[^a-z0-9]', '', ext.lower())[:5]\n",
        "                if not ext:\n",
        "                    ext = 'jpg'\n",
        "\n",
        "                filename = f\"url_image_{i+1}.{ext}\"\n",
        "                img_path = os.path.join(output_dir, filename)\n",
        "\n",
        "                with open(img_path, 'wb') as f:\n",
        "                    for chunk in img_response.iter_content(1024):\n",
        "                        f.write(chunk)\n",
        "\n",
        "                image_paths.append(img_path)\n",
        "                print(f\"Saved: {img_path}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error downloading {img_url}: {str(e)}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing URL: {str(e)}\")\n",
        "\n",
        "    return image_paths\n",
        "\n",
        "def extract_images_from_pdf(pdf_path, output_dir=\"extracted_images\"):\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    image_paths = []\n",
        "    is_url = pdf_path.startswith('http')\n",
        "\n",
        "    try:\n",
        "        if is_url:\n",
        "            response = requests.get(pdf_path, headers=HEADERS)\n",
        "            response.raise_for_status()\n",
        "            pdf_data = BytesIO(response.content)\n",
        "            doc = fitz.open(stream=pdf_data, filetype=\"pdf\")\n",
        "        else:\n",
        "            doc = fitz.open(pdf_path)\n",
        "\n",
        "        for page_num in range(len(doc)):\n",
        "            page = doc.load_page(page_num)\n",
        "            image_list = page.get_images(full=True)\n",
        "\n",
        "            for img_index, img in enumerate(image_list, start=1):\n",
        "                xref = img[0]\n",
        "                base_image = doc.extract_image(xref)\n",
        "                image_bytes = base_image[\"image\"]\n",
        "                ext = base_image[\"ext\"]\n",
        "\n",
        "                filename = f\"pdf_page{page_num+1}_img{img_index}.{ext}\"\n",
        "                img_path = os.path.join(output_dir, filename)\n",
        "\n",
        "                with open(img_path, \"wb\") as f:\n",
        "                    f.write(image_bytes)\n",
        "\n",
        "                image_paths.append(img_path)\n",
        "                print(f\"Saved: {img_path}\")\n",
        "\n",
        "        doc.close()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing PDF: {str(e)}\")\n",
        "\n",
        "    return image_paths\n",
        "\n",
        "def extract_images(input_source, output_dir=\"extracted_images\"):\n",
        "    if re.match(r'https?://', input_source, re.I):\n",
        "        print(f\"Processing URL: {input_source}\")\n",
        "        return extract_images_from_url(input_source, output_dir)\n",
        "    elif input_source.lower().endswith('.pdf'):\n",
        "        print(f\"Processing PDF: {input_source}\")\n",
        "        return extract_images_from_pdf(input_source, output_dir)\n",
        "    else:\n",
        "        raise ValueError(\"Input must be a valid URL or PDF file path\")"
      ],
      "metadata": {
        "id": "b71WhHgmi0lA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================\n",
        "# 2. MEDICAL CLASSIFIER\n",
        "# ======================\n",
        "class MedicalImageClassifier:\n",
        "    def __init__(self, model_path='best_model.h5', img_size=(224, 224)):\n",
        "        self.model = self.load_model(model_path)\n",
        "        self.img_size = img_size\n",
        "        self.class_names = ['Non-Medical', 'Medical']\n",
        "\n",
        "    def load_model(self, model_path):\n",
        "        \"\"\"Load model with multiple fallback strategies\"\"\"\n",
        "        try:\n",
        "            # First try loading normally\n",
        "            return tf.keras.models.load_model(model_path)\n",
        "        except:\n",
        "            try:\n",
        "                # Try with custom metrics\n",
        "                custom_objects = {\n",
        "                    'precision': tf.keras.metrics.Precision(name='precision'),\n",
        "                    'recall': tf.keras.metrics.Recall(name='recall'),\n",
        "                    'auc': tf.keras.metrics.AUC(name='auc')\n",
        "                }\n",
        "                return tf.keras.models.load_model(model_path, custom_objects=custom_objects)\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading model: {e}\")\n",
        "                print(\"Using MobileNetV2 as fallback model\")\n",
        "                # Create a simple fallback model\n",
        "                base_model = tf.keras.applications.MobileNetV2(\n",
        "                    input_shape=(224, 224, 3),\n",
        "                    include_top=False,\n",
        "                    weights='imagenet',\n",
        "                    pooling='avg'\n",
        "                )\n",
        "                base_model.trainable = False\n",
        "                model = tf.keras.Sequential([\n",
        "                    base_model,\n",
        "                    tf.keras.layers.Dropout(0.3),\n",
        "                    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "                ])\n",
        "                model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "                return model\n",
        "\n",
        "    def preprocess_image(self, image_path):\n",
        "        \"\"\"Robust image preprocessing with error handling\"\"\"\n",
        "        try:\n",
        "            img = cv2.imread(image_path)\n",
        "            if img is None:\n",
        "                raise ValueError(f\"Could not read image: {image_path}\")\n",
        "\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "            img = cv2.resize(img, self.img_size)\n",
        "            img = img / 255.0\n",
        "            return np.expand_dims(img, axis=0)\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {image_path}: {str(e)}\")\n",
        "            # Return a blank image as fallback\n",
        "            return np.zeros((1, *self.img_size, 3))\n",
        "\n",
        "    def predict(self, image_path):\n",
        "        \"\"\"Classify an image and return results\"\"\"\n",
        "        img = self.preprocess_image(image_path)\n",
        "        prob = self.model.predict(img, verbose=0)[0][0]\n",
        "        label = 1 if prob > 0.5 else 0\n",
        "\n",
        "        return {\n",
        "            'class': self.class_names[label],\n",
        "            'confidence': prob if label == 1 else 1 - prob,\n",
        "            'medical_probability': prob\n",
        "        }\n"
      ],
      "metadata": {
        "id": "XL5ZJFrsi0iT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================\n",
        "# 3. MAIN WORKFLOW\n",
        "# ======================\n",
        "def process_url(url, classifier):\n",
        "    \"\"\"Process a URL: extract images and classify them\"\"\"\n",
        "    print(f\"\\nExtracting images from URL: {url}\")\n",
        "    images = extract_images(url)\n",
        "\n",
        "    print(\"\\nClassifying images...\")\n",
        "    results = []\n",
        "    for img_path in tqdm(images):\n",
        "        try:\n",
        "            result = classifier.predict(img_path)\n",
        "            results.append({\n",
        "                'image': os.path.basename(img_path),\n",
        "                'prediction': result['class'],\n",
        "                'confidence': f\"{result['confidence']:.4f}\",\n",
        "                'medical_probability': f\"{result['medical_probability']:.4f}\"\n",
        "            })\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {img_path}: {str(e)}\")\n",
        "            results.append({\n",
        "                'image': os.path.basename(img_path),\n",
        "                'prediction': 'Error',\n",
        "                'confidence': '0.0000',\n",
        "                'medical_probability': '0.0000'\n",
        "            })\n",
        "\n",
        "    return results\n",
        "\n",
        "def process_pdf(pdf_file, classifier):\n",
        "    \"\"\"Process a PDF: extract images and classify them\"\"\"\n",
        "    # Save uploaded file\n",
        "    pdf_path = os.path.join('/content', pdf_file.name)\n",
        "    with open(pdf_path, 'wb') as f:\n",
        "        f.write(pdf_file.getbuffer())\n",
        "\n",
        "    print(f\"\\nExtracting images from PDF: {pdf_file.name}\")\n",
        "    images = extract_images(pdf_path)\n",
        "\n",
        "    print(\"\\nClassifying images...\")\n",
        "    results = []\n",
        "    medical_images = []\n",
        "\n",
        "    for img_path in tqdm(images):\n",
        "        try:\n",
        "            result = classifier.predict(img_path)\n",
        "            results.append({\n",
        "                'image': os.path.basename(img_path),\n",
        "                'prediction': result['class'],\n",
        "                'confidence': f\"{result['confidence']:.4f}\",\n",
        "                'medical_probability': f\"{result['medical_probability']:.4f}\"\n",
        "            })\n",
        "\n",
        "            # Save medical images with high confidence\n",
        "            if result['class'] == 'Medical' and result['medical_probability'] > 0.9:\n",
        "                medical_images.append(img_path)\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {img_path}: {str(e)}\")\n",
        "            results.append({\n",
        "                'image': os.path.basename(img_path),\n",
        "                'prediction': 'Error',\n",
        "                'confidence': '0.0000',\n",
        "                'medical_probability': '0.0000'\n",
        "            })\n",
        "\n",
        "    print(f\"\\nFound {len(medical_images)} high-confidence medical images\")\n",
        "    return results, medical_images"
      ],
      "metadata": {
        "id": "7FLEQz3ni0er"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================\n",
        "# 4. USER INTERFACE\n",
        "# ======================\n",
        "def main_menu():\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"MEDICAL IMAGE CLASSIFICATION SYSTEM\")\n",
        "    print(\"=\"*50)\n",
        "    print(\"1. Classify images from a URL\")\n",
        "    print(\"2. Classify images from a PDF file\")\n",
        "    print(\"3. Exit\")\n",
        "\n",
        "    choice = input(\"\\nEnter your choice (1-3): \")\n",
        "    return choice"
      ],
      "metadata": {
        "id": "H6tfwIQXi0bS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================\n",
        "# 5. INITIALIZATION\n",
        "# ======================\n",
        "# Initialize classifier with robust error handling\n",
        "try:\n",
        "    classifier = MedicalImageClassifier(model_path='best_model.h5')\n",
        "    print(\"Classifier loaded successfully\")\n",
        "except Exception as e:\n",
        "    print(f\"Error initializing classifier: {str(e)}\")\n",
        "    print(\"Using fallback classifier\")\n",
        "    classifier = MedicalImageClassifier()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzLsSZ9Ti0Yh",
        "outputId": "f0a4a78a-950d-444c-e267-1304718078b5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading model: Only input tensors may be passed as positional arguments. The following argument value should be passed as a keyword argument: 3.0 (of type <class 'float'>)\n",
            "Using MobileNetV2 as fallback model\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Classifier loaded successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================\n",
        "# 6. EXECUTION LOOP\n",
        "# ======================\n",
        "while True:\n",
        "    choice = main_menu()\n",
        "\n",
        "    if choice == '1':\n",
        "        url = input(\"\\nEnter URL to process: \")\n",
        "        results = process_url(url, classifier)\n",
        "\n",
        "        # Create and display results\n",
        "        results_df = pd.DataFrame(results)\n",
        "        print(\"\\nClassification Results:\")\n",
        "        print(results_df)\n",
        "\n",
        "        # Save results\n",
        "        csv_path = \"url_classification_results.csv\"\n",
        "        results_df.to_csv(csv_path, index=False)\n",
        "        print(f\"\\nResults saved to {csv_path}\")\n",
        "\n",
        "        # Download results\n",
        "        files.download(csv_path)\n",
        "\n",
        "    elif choice == '2':\n",
        "        print(\"\\nUpload a PDF file:\")\n",
        "        pdf_files = files.upload()\n",
        "\n",
        "        if pdf_files:\n",
        "            pdf_name = list(pdf_files.keys())[0]\n",
        "            pdf_file = pdf_files[pdf_name]\n",
        "\n",
        "            results, medical_images = process_pdf(\n",
        "                type('PDFFile', (object,), {'name': pdf_name, 'getbuffer': lambda: pdf_file}),\n",
        "                classifier\n",
        "            )\n",
        "\n",
        "            # Create and display results\n",
        "            results_df = pd.DataFrame(results)\n",
        "            print(\"\\nClassification Results:\")\n",
        "            print(results_df)\n",
        "\n",
        "            # Save results\n",
        "            csv_path = \"pdf_classification_results.csv\"\n",
        "            results_df.to_csv(csv_path, index=False)\n",
        "            print(f\"\\nResults saved to {csv_path}\")\n",
        "\n",
        "            # Download results\n",
        "            files.download(csv_path)\n",
        "\n",
        "            # Create zip of medical images\n",
        "            if medical_images:\n",
        "                # Create a separate directory for medical images\n",
        "                os.makedirs('medical_images', exist_ok=True)\n",
        "                for img_path in medical_images:\n",
        "                    try:\n",
        "                        shutil.copy(img_path, 'medical_images')\n",
        "                    except:\n",
        "                        pass\n",
        "\n",
        "                # Create zip\n",
        "                shutil.make_archive('medical_images', 'zip', 'medical_images')\n",
        "                print(\"\\nDownloading medical images...\")\n",
        "                files.download('medical_images.zip')\n",
        "\n",
        "    elif choice == '3':\n",
        "        print(\"\\nExiting program...\")\n",
        "        break\n",
        "\n",
        "    else:\n",
        "        print(\"\\nInvalid choice. Please try again.\")\n",
        "\n",
        "print(\"\\nProcessing complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "j_Lj2UO9i0VW",
        "outputId": "deb5615b-445e-4130-925d-3b6587a7170c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "MEDICAL IMAGE CLASSIFICATION SYSTEM\n",
            "==================================================\n",
            "1. Classify images from a URL\n",
            "2. Classify images from a PDF file\n",
            "3. Exit\n",
            "\n",
            "Enter your choice (1-3): 1\n",
            "\n",
            "Enter URL to process: https://ss-2005.github.io/Sahil-Shaikh-Portfolio/\n",
            "\n",
            "Extracting images from URL: https://ss-2005.github.io/Sahil-Shaikh-Portfolio/\n",
            "Processing URL: https://ss-2005.github.io/Sahil-Shaikh-Portfolio/\n",
            "Saved: extracted_images/url_image_1.jpeg\n",
            "Saved: extracted_images/url_image_2.jpeg\n",
            "Saved: extracted_images/url_image_3.jpeg\n",
            "Saved: extracted_images/url_image_4.jpeg\n",
            "Saved: extracted_images/url_image_5.jpeg\n",
            "Saved: extracted_images/url_image_6.jpeg\n",
            "Saved: extracted_images/url_image_7.jpeg\n",
            "Saved: extracted_images/url_image_8.jpeg\n",
            "Saved: extracted_images/url_image_9.jpeg\n",
            "Saved: extracted_images/url_image_10.jpeg\n",
            "Saved: extracted_images/url_image_11.jpeg\n",
            "Saved: extracted_images/url_image_12.jpeg\n",
            "Saved: extracted_images/url_image_13.jpeg\n",
            "Saved: extracted_images/url_image_14.jpeg\n",
            "Saved: extracted_images/url_image_15.jpeg\n",
            "Saved: extracted_images/url_image_16.jpeg\n",
            "Saved: extracted_images/url_image_17.jpeg\n",
            "Saved: extracted_images/url_image_18.jpeg\n",
            "Saved: extracted_images/url_image_19.jpeg\n",
            "Saved: extracted_images/url_image_20.jpeg\n",
            "Saved: extracted_images/url_image_21.jpeg\n",
            "Saved: extracted_images/url_image_22.jpeg\n",
            "Saved: extracted_images/url_image_23.jpeg\n",
            "Saved: extracted_images/url_image_24.jpeg\n",
            "Saved: extracted_images/url_image_25.jpeg\n",
            "Saved: extracted_images/url_image_26.jpeg\n",
            "Saved: extracted_images/url_image_27.jpeg\n",
            "Saved: extracted_images/url_image_28.jpeg\n",
            "Saved: extracted_images/url_image_29.jpeg\n",
            "Saved: extracted_images/url_image_30.jpeg\n",
            "Saved: extracted_images/url_image_31.jpeg\n",
            "\n",
            "Classifying images...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 31/31 [00:06<00:00,  4.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Results:\n",
            "                image   prediction confidence medical_probability\n",
            "0    url_image_1.jpeg      Medical     0.5072              0.5072\n",
            "1    url_image_2.jpeg  Non-Medical     0.8310              0.1690\n",
            "2    url_image_3.jpeg  Non-Medical     0.5707              0.4293\n",
            "3    url_image_4.jpeg      Medical     0.5978              0.5978\n",
            "4    url_image_5.jpeg  Non-Medical     0.6125              0.3875\n",
            "5    url_image_6.jpeg  Non-Medical     0.5636              0.4364\n",
            "6    url_image_7.jpeg  Non-Medical     0.7520              0.2480\n",
            "7    url_image_8.jpeg  Non-Medical     0.7423              0.2577\n",
            "8    url_image_9.jpeg  Non-Medical     0.7026              0.2974\n",
            "9   url_image_10.jpeg  Non-Medical     0.6704              0.3296\n",
            "10  url_image_11.jpeg      Medical     0.6240              0.6240\n",
            "11  url_image_12.jpeg  Non-Medical     0.6317              0.3683\n",
            "12  url_image_13.jpeg  Non-Medical     0.7018              0.2982\n",
            "13  url_image_14.jpeg  Non-Medical     0.8878              0.1122\n",
            "14  url_image_15.jpeg  Non-Medical     0.5052              0.4948\n",
            "15  url_image_16.jpeg  Non-Medical     0.5306              0.4694\n",
            "16  url_image_17.jpeg  Non-Medical     0.6401              0.3599\n",
            "17  url_image_18.jpeg      Medical     0.8671              0.8671\n",
            "18  url_image_19.jpeg  Non-Medical     0.8098              0.1902\n",
            "19  url_image_20.jpeg  Non-Medical     0.7296              0.2704\n",
            "20  url_image_21.jpeg  Non-Medical     0.7236              0.2764\n",
            "21  url_image_22.jpeg      Medical     0.5708              0.5708\n",
            "22  url_image_23.jpeg  Non-Medical     0.5615              0.4385\n",
            "23  url_image_24.jpeg  Non-Medical     0.5405              0.4595\n",
            "24  url_image_25.jpeg      Medical     0.5371              0.5371\n",
            "25  url_image_26.jpeg      Medical     0.5050              0.5050\n",
            "26  url_image_27.jpeg      Medical     0.5330              0.5330\n",
            "27  url_image_28.jpeg  Non-Medical     0.6321              0.3679\n",
            "28  url_image_29.jpeg      Medical     0.8919              0.8919\n",
            "29  url_image_30.jpeg  Non-Medical     0.7238              0.2762\n",
            "30  url_image_31.jpeg  Non-Medical     0.5946              0.4054\n",
            "\n",
            "Results saved to url_classification_results.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_75f99ef5-e540-4608-8d5f-5c7b23b28dd7\", \"url_classification_results.csv\", 1367)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "MEDICAL IMAGE CLASSIFICATION SYSTEM\n",
            "==================================================\n",
            "1. Classify images from a URL\n",
            "2. Classify images from a PDF file\n",
            "3. Exit\n",
            "\n",
            "Enter your choice (1-3): 2\n",
            "\n",
            "Upload a PDF file:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-818a9b1e-c342-45cc-bfee-7a53dcd2ce9e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-818a9b1e-c342-45cc-bfee-7a53dcd2ce9e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving image-based-pdf-sample.pdf to image-based-pdf-sample.pdf\n",
            "\n",
            "Extracting images from PDF: image-based-pdf-sample.pdf\n",
            "Processing PDF: /content/image-based-pdf-sample.pdf\n",
            "Saved: extracted_images/pdf_page1_img1.jpeg\n",
            "\n",
            "Classifying images...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Found 0 high-confidence medical images\n",
            "\n",
            "Classification Results:\n",
            "                 image   prediction confidence medical_probability\n",
            "0  pdf_page1_img1.jpeg  Non-Medical     0.6511              0.3489\n",
            "\n",
            "Results saved to pdf_classification_results.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ad5e57b5-7a19-41c5-bba4-19e4f3553025\", \"pdf_classification_results.csv\", 94)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "MEDICAL IMAGE CLASSIFICATION SYSTEM\n",
            "==================================================\n",
            "1. Classify images from a URL\n",
            "2. Classify images from a PDF file\n",
            "3. Exit\n",
            "\n",
            "Enter your choice (1-3): 3\n",
            "\n",
            "Exiting program...\n",
            "\n",
            "Processing complete!\n"
          ]
        }
      ]
    }
  ]
}